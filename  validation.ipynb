{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff421293",
   "metadata": {},
   "source": [
    "# North American data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2210c1",
   "metadata": {},
   "source": [
    "## What is done \n",
    "1. Importing file from the folder\n",
    "2. Doing some EDA\n",
    "3. Renaming colums\n",
    "4. Applying the validation rules\n",
    "5. exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the supplier name\n",
    "file_name = input(\"Enter the source name: \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9da908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with DataFrames and Supporting array operations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# patterns matching\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Handles file and directory operations\n",
    "import os\n",
    "\n",
    "\n",
    "# accessing to system-specific parameters and functions.\n",
    "import sys\n",
    "\n",
    "# Reads, writes, and modifies Excel files.\n",
    "import openpyxl\n",
    "\n",
    "# Handling file and directory operations like copying and moving files.\n",
    "import shutil\n",
    "\n",
    "# Creates a new Excel workbook and Opens an existing Excel file.\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# filling cells with colors or patterns.\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Converting a column index to an Excel-style column letter\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.utils.cell import get_column_letter\n",
    "\n",
    "#  handling dates and times.\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b052be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path where the files are located\n",
    "folder_path = r\"\\\\Enter the path\"\n",
    "\n",
    "# Define file patterns\n",
    "file_patterns = [f\"{folder_path}/*.csv\", f\"{folder_path}/*.xlsx\", f\"{folder_path}/*.xls\", f\"{folder_path}/*.tsv\"]\n",
    "\n",
    "# Get all matching files\n",
    "files = []\n",
    "for pattern in file_patterns:\n",
    "    files.extend(glob.glob(pattern))\n",
    "\n",
    "# Iterate through each file \n",
    "for file_path in files:\n",
    "    ext = file_path.split(\".\")[-1].lower()  # Get lowercase file extension\n",
    "\n",
    "    if ext == \"csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded CSV file: {file_path}\")\n",
    "\n",
    "    elif ext in [\"xlsx\", \"xls\"]:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"Loaded Excel file: {file_path}\")\n",
    "\n",
    "    elif ext == \"tsv\":\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "        print(f\"Loaded TSV file: {file_path}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the sheet for customer data\n",
    "# df = pd.read_excel(file_path, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the first row contains the word \"Required\"\n",
    "if df.iloc[0].str.contains(\"Required\").any():\n",
    "    # Skip the first row\n",
    "    df = df.iloc[1:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total rows and columns of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da451fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(re.search(r'country|country code', str(col), re.IGNORECASE) for col in df.columns):\n",
    "    print(\"Country column is present\")\n",
    "else:\n",
    "    print(\"Country column is NOT present\")\n",
    "    df[\"country code\"] = \"CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095da5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all row with NaN\n",
    "df = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all cloumns with NaN\n",
    "df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42364579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summery of the data\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of nulls in each columns\n",
    "null_columns = df.isnull().sum()\n",
    "null_columns = null_columns[null_columns > 0]\n",
    "count_of_null = null_columns.reset_index()\n",
    "count_of_null.columns = ['Column_Name', 'Null_Count']\n",
    "count_of_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41907c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns\n",
    "def map_location_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Re-maps location-related column names in a DataFrame to standardized labels\n",
    "    such as 'Address', 'City', 'ZipCode', 'Region', and 'Country'.\n",
    "    \"\"\"\n",
    "    import unicodedata\n",
    "\n",
    "    # Define a mapping dictionary based on substrings\n",
    "    rename_map = {\n",
    "        'address': 'Address',\n",
    "        'street': 'Address',\n",
    "        'city': 'City',\n",
    "        'zip': 'ZipCode',\n",
    "        'postal': 'ZipCode',\n",
    "        'state': 'Region',\n",
    "        'province': 'Region',\n",
    "        'region': 'Region',\n",
    "        'country': 'Country_code',\n",
    "        'nation': 'Country'\n",
    "    }\n",
    "\n",
    "    def normalize_column(col):\n",
    "        # Remove accents and lowercase\n",
    "        col_norm = unicodedata.normalize('NFKD', col).encode('ascii', 'ignore').decode().lower()\n",
    "        for keyword, standard in rename_map.items():\n",
    "            if keyword in col_norm:\n",
    "                return standard\n",
    "        return col  # Return original if no match found\n",
    "\n",
    "    # Apply the renaming\n",
    "    new_columns = [normalize_column(col) for col in df.columns]\n",
    "    df_renamed = df.copy()\n",
    "    df_renamed.columns = new_columns\n",
    "\n",
    "    return df_renamed\n",
    "\n",
    "# Example usage:\n",
    "# df_clean = map_location_columns(raw_df)\n",
    "# print(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the country_code\n",
    "df1['Country_Code'] = df1['Country_Code'].astype(str).str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean post code\n",
    "df1['Zip/Postal Code'] = df1['Zip/Postal Code'].astype(str).str.replace(r\"[.,'!]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_address_record(record, valid_postal_codes, region_aliases, postal_to_region_map):\n",
    "    \"\"\"\n",
    "    Validates a single address record using several quality rules:\n",
    "    - Country must be Canada (by name or code)\n",
    "    - Postal code should be non-empty, valid, and format compliant\n",
    "    - City and street must be sufficiently detailed\n",
    "    - Region should be recognized and should align with the postal code\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_valid_country(value):\n",
    "        val = str(value).strip().lower()\n",
    "        return val in {'ca', 'can', 'canada'}\n",
    "    \n",
    "    def is_valid_postcode(postal_code):\n",
    "        if pd.isna(postal_code):\n",
    "            return False\n",
    "        code = str(postal_code).replace(\" \", \"\").lower()\n",
    "        return code in valid_postal_codes\n",
    "    \n",
    "    def is_format_compliant(postal_code):\n",
    "        pattern = r'^[A-Za-z]\\d[A-Za-z][ -]?\\d[A-Za-z]\\d$'\n",
    "        return bool(re.fullmatch(pattern, str(postal_code).strip()))\n",
    "    \n",
    "    def is_valid_city(city):\n",
    "        return isinstance(city, str) and len(city.strip()) > 3\n",
    "\n",
    "    def is_valid_street(address):\n",
    "        return isinstance(address, str) and 3 < len(address.strip()) <= 100\n",
    "\n",
    "    def is_recognized_region(region):\n",
    "        return str(region).strip().lower() in region_aliases\n",
    "\n",
    "    def region_matches_postal(postal_code, region):\n",
    "        code = str(postal_code).replace(\" \", \"\").lower()\n",
    "        region_norm = str(region).strip().lower()\n",
    "        expected = postal_to_region_map.get(code)\n",
    "        return expected and (region_norm == expected or region_norm in region_aliases)\n",
    "\n",
    "    return pd.Series([\n",
    "        is_valid_country(record.get('Country')),\n",
    "        is_valid_postcode(record.get('PostalCode')),\n",
    "        is_valid_city(record.get('City')),\n",
    "        is_valid_street(record.get('Street')),\n",
    "        is_recognized_region(record.get('Region')),\n",
    "        region_matches_postal(record.get('PostalCode'), record.get('Region')),\n",
    "        is_format_compliant(record.get('PostalCode'))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da3fd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_postcodes_file = r'\\\\Enter the path'\n",
    "postalcode_data = pd.read_csv(valid_postcodes_file)\n",
    "# Normalize valid postcodes\n",
    "valid_postcodes = postalcode_data['postalcode'] \\\n",
    "    .astype(str) \\\n",
    "    .str.replace(\" \", \"\") \\\n",
    "    .str.lower() \\\n",
    "    .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from postal code to province\n",
    "postcode_to_province_mapping = dict(zip(\n",
    "    postalcode_data['postalcode'].str.replace(\" \", \"\").str.lower(),\n",
    "    postalcode_data['province'].str.strip().str.lower()\n",
    "))\n",
    "\n",
    "# Create province mapping (full name and short code)\n",
    "province_mapping = set(\n",
    "    postalcode_data['province'].str.strip().str.lower().tolist() + \n",
    "    postalcode_data['provincecode'].str.strip().str.lower().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Return the columns\n",
    "df1[['CountryCodeValid', \n",
    "     'ZipPostalCodePopulated', \n",
    "     'PostalCodeInListValid', \n",
    "     'CityValid', \n",
    "     'StreetAddressValid', \n",
    "     'ProvinceValid', \n",
    "     'PostcodeMatchesProvince', \n",
    "     'PostalCodeFormatValid']] = df1.apply(\n",
    "    lambda row: validate_record(row, \n",
    "                                valid_postcodes=valid_postcodes, \n",
    "                                province_mapping=province_mapping, \n",
    "                                postcode_to_province_mapping=postcode_to_province_mapping), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da13aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an bool column PassFail\n",
    "df1['PassFail'] = df1[['CountryCodeValid', 'ZipPostalCodePopulated', 'PostalCodeInListValid', \n",
    "                       'CityValid', 'StreetAddressValid','PostcodeMatchesProvince','PostalCodeFormatValid']].all(axis=1).map({True: 'Pass', False: 'Fail'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd60a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the postal code format\n",
    "df1['PostalCodeStatus'] = np.where(\n",
    "    (df1['PostalCodeFormatValid'] == True) & (df1['PostalCodeInListValid'] == True), \"Valid\",\n",
    "    np.where(\n",
    "        (df1['PostalCodeFormatValid'] == True) & (df1['PostalCodeInListValid'] == False), \"Could be valid please check\",\n",
    "        \"Not Valid\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f303b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ProvienceValid Column\n",
    "df_result = df1.drop(columns=['ProvinceValid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b65f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a78c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Placing the generated file in the folder\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "output_file_path = rf'\\\\path\\CA_validation_OUT\\{file_name}_validation__{current_date}.xlsx'\n",
    "df_result.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define styles\n",
    "valid_fill = PatternFill(start_color=\"C6EFCE\", end_color=\"C6EFCE\", fill_type=\"solid\")  # Green\n",
    "invalid_fill = PatternFill(start_color=\"FFC7CE\", end_color=\"FFC7CE\", fill_type=\"solid\")  # Red\n",
    "pass_fill = PatternFill(start_color=\"66CDAA\", end_color=\"66CDAA\", fill_type=\"solid\")  # Medium Green\n",
    "fail_fill = PatternFill(start_color=\"CD5C5C\", end_color=\"CD5C5C\", fill_type=\"solid\")  # Dark Red\n",
    "\n",
    "# Define styles for PostalCodeStatus\n",
    "could_be_valid_soft_blue = PatternFill(start_color=\"A9D0F5\", end_color=\"A9D0F5\", fill_type=\"solid\")  # Light Blue\n",
    "not_valid_light_orange = PatternFill(start_color=\"FFDAB9\", end_color=\"FFDAB9\", fill_type=\"solid\")  # Light Orange\n",
    "valid_soft_green = PatternFill(start_color=\"C6EFCE\", end_color=\"C6EFCE\", fill_type=\"solid\")  # Green\n",
    "\n",
    "\n",
    "# Load workbook\n",
    "wb = openpyxl.load_workbook(output_file_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Map headers to columns in the worksheet\n",
    "headers = {cell.value: cell.column for cell in ws[1]}  # Assumes the first row is the header\n",
    "\n",
    "# Columns to format\n",
    "columns_to_format = ['CountryCodeValid', 'ZipPostalCodePopulated', 'PostalCodeInListValid', \n",
    "                     'CityValid', 'StreetAddressValid', 'PostcodeMatchesProvince', 'PostalCodeFormatValid']\n",
    "pass_fail_col = 'PassFail'\n",
    "postalcodestats_col = 'PostalCodeStatus'  # Column for PostalCodeStatus formatting\n",
    "\n",
    "# Check if all required columns exist in the worksheet\n",
    "for col in columns_to_format + [pass_fail_col, postalcodestats_col]:\n",
    "    if col not in headers:\n",
    "        raise ValueError(f\"Column '{col}' not found in worksheet headers\")\n",
    "\n",
    "# Iterate over rows and apply formatting\n",
    "for row in ws.iter_rows(min_row=2, max_row=ws.max_row):  # Skip header row\n",
    "    # Apply formatting to the columns in bulk\n",
    "    for col in columns_to_format:\n",
    "        cell = row[headers[col] - 1]  # Adjust for 0-based index\n",
    "        if cell.value:  # Assume valid if True or non-empty\n",
    "            cell.fill = valid_fill\n",
    "        else:\n",
    "            cell.fill = invalid_fill\n",
    "\n",
    "    # Format PassFail column\n",
    "    pass_fail_cell = row[headers[pass_fail_col] - 1]  # Adjust for 0-based index\n",
    "    if pass_fail_cell.value == 'Pass':\n",
    "        pass_fail_cell.fill = pass_fill\n",
    "    else:\n",
    "        pass_fail_cell.fill = fail_fill\n",
    "\n",
    "    # Apply color to PostalCodeStatus column\n",
    "    postalcodestats_cell = row[headers[postalcodestats_col] - 1]\n",
    "    if postalcodestats_cell.value == \"Valid\":\n",
    "        postalcodestats_cell.fill = valid_soft_green\n",
    "    elif postalcodestats_cell.value == \"Not Valid\":\n",
    "        postalcodestats_cell.fill = not_valid_light_orange\n",
    "    elif postalcodestats_cell.value == \"Could be valid please check\":\n",
    "        postalcodestats_cell.fill = could_be_valid_soft_blue\n",
    "\n",
    "# Save workbook after all changes\n",
    "wb.save(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
